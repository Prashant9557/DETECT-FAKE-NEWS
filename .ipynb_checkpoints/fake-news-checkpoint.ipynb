{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e344b66a-b165-48a6-917f-c3e85b398310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.11.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "461d14d5-0a1b-4159-b3e1-eb560a58d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 24353\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 8117\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "        num_rows: 8117\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"GonzaloA/fake_news\")\n",
    "\n",
    "# Display the dataset structure\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b816328d-22b6-474d-a747-195cebbc1976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'title': ' ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)', 'text': 'Maury is perhaps one of the trashiest shows on television today. It s right in line with the likes of the gutter trash that is Jerry Springer, and the fact that those shows are still on the air with the shit they air really is a sad testament to what Americans find to be entertaining. However, Maury really crossed the line with a Facebook post regarding one of their guest s appearance with a vile, disgusting caption on Tuesday evening.There was a young woman on there doing one of their episodes regarding the paternity of her child. However, on the page, the show posted an image of the woman, who happens to bear a striking resemblance to Senator and presidential candidate Ted Cruz. The caption from the Maury Show page read: The Lie Detector Test determined .that was a LIE!  Ted Cruz is just NOT that SEXY! As if that weren t horrible enough, the caption underneath the Imgur upload reads,  Ted Cruz in drag on Maury. Here is an image from the official Maury Facebook page:Here is the embed of the post itself:This is beyond despicable. It s bad enough that this show preys on desperate people to keep their trashy show going and their audience of bottom-feeders entertained, but now they publicly mock them as well? This young woman cannot help how she looks or who she resembles. That is not her fault. Shaming someone s looks on social media is something we d expect from the morons who watch this crap on a daily basis, but it is NOT something the official show page should be doing. Then again, what can you expect from a show that rolls in the mud for a living and continues to show the world that there is now low they will not stoop to? This was more than a step too far, though.Maury, you owe this young woman a public apology. A VERY public apology. There s just no excuse for this, no matter the demographics of your audience or what you do on that disgusting show of yours. I suppose it will be too much to ask that you lose viewers over this, because the people who watch your trashy ass show likely aren t educated enough to understand why this is so wrong in the first place. I don t watch, so I can t deprive you of my viewership, but I CAN call you out.Shame on you, Maury Show and everyone associated with this despicable Facebook post. You really showed your true colors here today.Featured image via Facebook ', 'label': 0}\n",
      "{'Unnamed: 0': [0, 1, 2, 3, 4], 'title': [' ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)', ' Trump’s Favorite News Channel Tries To Soothe His Battered Ego – Gets Taken To The Cleaners', 'Russia warns Iraq, Kurds not to destabilize Middle East after Kurdish vote', 'WATCH STEVE SCALISE Throw A Strike At The Nationals Baseball Game [Video]', ' Trump Will HATE What Stephen Colbert Just Did To Him – It’s Pure Comedy Genius (VIDEO)'], 'text': ['Maury is perhaps one of the trashiest shows on television today. It s right in line with the likes of the gutter trash that is Jerry Springer, and the fact that those shows are still on the air with the shit they air really is a sad testament to what Americans find to be entertaining. However, Maury really crossed the line with a Facebook post regarding one of their guest s appearance with a vile, disgusting caption on Tuesday evening.There was a young woman on there doing one of their episodes regarding the paternity of her child. However, on the page, the show posted an image of the woman, who happens to bear a striking resemblance to Senator and presidential candidate Ted Cruz. The caption from the Maury Show page read: The Lie Detector Test determined .that was a LIE!  Ted Cruz is just NOT that SEXY! As if that weren t horrible enough, the caption underneath the Imgur upload reads,  Ted Cruz in drag on Maury. Here is an image from the official Maury Facebook page:Here is the embed of the post itself:This is beyond despicable. It s bad enough that this show preys on desperate people to keep their trashy show going and their audience of bottom-feeders entertained, but now they publicly mock them as well? This young woman cannot help how she looks or who she resembles. That is not her fault. Shaming someone s looks on social media is something we d expect from the morons who watch this crap on a daily basis, but it is NOT something the official show page should be doing. Then again, what can you expect from a show that rolls in the mud for a living and continues to show the world that there is now low they will not stoop to? This was more than a step too far, though.Maury, you owe this young woman a public apology. A VERY public apology. There s just no excuse for this, no matter the demographics of your audience or what you do on that disgusting show of yours. I suppose it will be too much to ask that you lose viewers over this, because the people who watch your trashy ass show likely aren t educated enough to understand why this is so wrong in the first place. I don t watch, so I can t deprive you of my viewership, but I CAN call you out.Shame on you, Maury Show and everyone associated with this despicable Facebook post. You really showed your true colors here today.Featured image via Facebook ', 'Yesterday, after the father of one of the UCLA players arrested in China failed to show Trump proper gratitude for getting his kid released, Trump, predictably, went to Twitter to grouse about it. He seems to expect to be worshiped for his help on this matter, but LaVar Ball wouldn t do it, so Trump tweeted:Now that the three basketball players are out of China and saved from years in jail, LaVar Ball, the father of LiAngelo, is unaccepting of what I did for his son and that shoplifting is no big deal. I should have left them in jail!  Donald J. Trump (@realDonaldTrump) November 19, 2017Fox News put that tweet into a meme portraying Trump as a strong, decisive leader and the UCLA basketball players as weaklings, because of course they did. Then they asked:  Do you agree with President Trump? Yes. Fox News seriously asked people whether they agree that Trump should have left them in jail because the father of one is refusing to show proper gratitude:Do you agree with President @realDonaldTrump? pic.twitter.com/p3VdoXPxPG  Fox News (@FoxNews) November 20, 2017And Twitter is just not having this at all:Nope. He needs adoration- sign of insecurity. That s why he mocks others. Worthless. pic.twitter.com/XpI18s83Wx  Billy Depp (@ucla_007) November 20, 2017I ve never seen a Fox tweet critical of the president.All Fox is does is aid and abet insanity, hate and divisiveness that hurts America. pic.twitter.com/HrsATfLSMI  American Patriot (@RealPatriot1976) November 20, 2017It s all relative. Shoplifting is a crime but its totally eclipsed by Trump University.  Cody Swan (@Lampliighter) November 20, 2017Yeah, POTUS should only do his job if he gets his ass kissed properly. Are you high?  Bill Raudenbush (@CandidateBill) November 20, 2017No. He s a child!  Opinionated (@letmesharewithu) November 20, 2017nah i know what public service means   o  (@geofftype) November 20, 2017I think he should stop being petty af. I don t care to hear about this from the President of the United States. He s so insecure, it s beyond troubling.  Keisha Venezio (@keishhhha) November 20, 2017No, I don t agree  pic.twitter.com/7N9KI0oTxl  Kelly H (@Kellyk1969) November 20, 2017Do you agree with President @realDonaldTrump? pic.twitter.com/p3VdoXPxPG  Fox News (@FoxNews) November 20, 2017Nope. I personally would be extraordinarily appreciative if this happened to one of my kids, but i think it s shameful that the prez resents not being thanked enough and doesn t view helping Americans as just part of the job.  Liberal Kansan (@pvliberal) November 20, 2017NO Disgusting & embarrassing!  Melanie (@Melanie03630436) November 20, 2017Well, I m not convinced that he single-handedly got them out of jail  so the question isn t really valid  Isaac Simonelli (@DiceTravels) November 20, 2017No normal person does. And YOU know it.  Ernie Page (@AngryHatter) November 20, 2017What?! This man is a child in a rumpled suit. In case you haven t noticed, hardly anybody likes him. : Thus, when you give to the needy, sound no trumpet before you, as the hypocrites do in the synagogues and in the streets, that they may be praised by others.  pic.twitter.com/ntJzgkdWdz  DEMOS..We the people (@Windemere22) November 20, 2017China should have thrown #Dotard @realDonaldTrump into the slammer, chucked the key into the bog & flushed it away.  Holger  \\\\_( )_/  (@hnelke1973) November 20, 2017No. @realDonaldTrump has no idea what it means to do good for the sake of doing good. He is an empty shell of a man with no moral compass. Also not my favorite president.  Doreen Graham (@DoreeGraham) November 20, 2017Absolutely not. The fact that our narcissistic baby in chief can t take any criticism without lashing out is disgraceful. We deserve better  erin o (@erin0331) November 20, 2017Typical trump .. always about himself forgetting America is for all  SARA_PDaily (@sarapdaily) November 20, 2017Typical trump .. always about himself forgetting America is for all  SARA_PDaily (@sarapdaily) November 20, 2017Why would anyone agree with this shit? Remember when we mourned the death of the student who died in NK and now we re talking about this?  Aditya Sharma (@adityaksharma) November 20, 2017No I do not agree with Donald. As a matter of fact, I wish he was left in the hospital at the time of his birth.  RABell (@R_A_Bell) November 20, 2017President Man-Baby needs to grow up. And Fox News needs to stop feeding his bullshit.Featured image via Alex Wong/Getty Images', 'MOSCOW (Reuters) - Russia on Wednesday warned Iraq and the Kurds against taking any steps that might destabilize the Middle East after a Kurdish independence referendum, encouraging both sides to hold talks to find a solution within the framework of a single Iraqi state. The Russian Foreign Ministry, in the same statement, also said that while Moscow respected the Kurds  national ambitions it favored preserving the territorial integrity of Iraq. ', \"House Majority Whip Steve Scalise (R., La.) threw a strike in his ceremonial first pitch at the Washington National s opening-round playoff game Friday night, which was also his birthday.Scalise was shot in the hip and nearly died in June and he had to throw from a walker but he had no trouble delivering a perfect pitch to Capitol police special agent David Bailey, who was also injured in the shooting.After taking a bullet on a field in Alexandria, Va., Scalise was visibly happy to return to the diamond, and he expressed his gratefulness on Twitter after.What a memorable birthday! I threw the first pitch at tonight's @Nationals vs. @Cubs #NLDS game! pic.twitter.com/1F7XrRGwiP  Rep. Steve Scalise (@SteveScalise) October 7, 2017Scalise returned to the House of Representatives last week to warm greetings from his colleagues, and he expressed thankfulness for his recovery. It s only strengthened my faith in God, and it s really crystallized what shows up as the goodness in people,  he said.  I got to see that goodness in people, and so while some people might focus on a tragic event and an evil act, to me, all I ll remember are the thousands of acts and kindness and love that came out of this.  Read more: WFB\", 'It can be said that Late Show host Stephen Colbert clearly gives no f*cks about what Donald Trump thinks of him. In addition, if Trump were to decide to angry-tweet Colbert in retaliation, you know that Colbert would wear that Twitter fit as a badge of honor, as he should.Absolutely annihilating Trump, his connection to Putin, the Russian prostitute story, the fact that he wants to take a mini-vacation after the inauguration, and the fact that, well, he s clearly full of sh*t, Colbert didn t hold back even bringing God, yes that God almighty with a gun, into the mix.Colbert even brought up the fact that Trump s approval ratings are absolutely pathetic, especially when compared to President Obama s approval rating upon entering office. Not only that, but Colbert had to admit something terrible   that he and white supremacists have one thing in common, they are absolutely disappointed in Trump   albeit clearly for different reasons.The Late Show host even pointed out that Trump will blame everything on being rigged if it doesn t go his way. Even if the weather is bad on Inauguration Day, that s clearly a conspiracy against him.Watch Colbert absolutely shred Trump here:Featured image via video screen capture'], 'label': [0, 0, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# View the first example in the dataset\n",
    "print(ds[\"train\"][0])\n",
    "\n",
    "# View the first five examples\n",
    "print(ds[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "21491148-68ac-424f-9175-b2eb1752327a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': [0, 1, 2, 3, 4], 'title': [' ‘Maury’ Show Official Facebook Posts F*CKED UP Caption On Guest That Looks Like Ted Cruz (IMAGE)', ' Trump’s Favorite News Channel Tries To Soothe His Battered Ego – Gets Taken To The Cleaners', 'Russia warns Iraq, Kurds not to destabilize Middle East after Kurdish vote', 'WATCH STEVE SCALISE Throw A Strike At The Nationals Baseball Game [Video]', ' Trump Will HATE What Stephen Colbert Just Did To Him – It’s Pure Comedy Genius (VIDEO)'], 'text': ['Maury is perhaps one of the trashiest shows on television today. It s right in line with the likes of the gutter trash that is Jerry Springer, and the fact that those shows are still on the air with the shit they air really is a sad testament to what Americans find to be entertaining. However, Maury really crossed the line with a Facebook post regarding one of their guest s appearance with a vile, disgusting caption on Tuesday evening.There was a young woman on there doing one of their episodes regarding the paternity of her child. However, on the page, the show posted an image of the woman, who happens to bear a striking resemblance to Senator and presidential candidate Ted Cruz. The caption from the Maury Show page read: The Lie Detector Test determined .that was a LIE!  Ted Cruz is just NOT that SEXY! As if that weren t horrible enough, the caption underneath the Imgur upload reads,  Ted Cruz in drag on Maury. Here is an image from the official Maury Facebook page:Here is the embed of the post itself:This is beyond despicable. It s bad enough that this show preys on desperate people to keep their trashy show going and their audience of bottom-feeders entertained, but now they publicly mock them as well? This young woman cannot help how she looks or who she resembles. That is not her fault. Shaming someone s looks on social media is something we d expect from the morons who watch this crap on a daily basis, but it is NOT something the official show page should be doing. Then again, what can you expect from a show that rolls in the mud for a living and continues to show the world that there is now low they will not stoop to? This was more than a step too far, though.Maury, you owe this young woman a public apology. A VERY public apology. There s just no excuse for this, no matter the demographics of your audience or what you do on that disgusting show of yours. I suppose it will be too much to ask that you lose viewers over this, because the people who watch your trashy ass show likely aren t educated enough to understand why this is so wrong in the first place. I don t watch, so I can t deprive you of my viewership, but I CAN call you out.Shame on you, Maury Show and everyone associated with this despicable Facebook post. You really showed your true colors here today.Featured image via Facebook ', 'Yesterday, after the father of one of the UCLA players arrested in China failed to show Trump proper gratitude for getting his kid released, Trump, predictably, went to Twitter to grouse about it. He seems to expect to be worshiped for his help on this matter, but LaVar Ball wouldn t do it, so Trump tweeted:Now that the three basketball players are out of China and saved from years in jail, LaVar Ball, the father of LiAngelo, is unaccepting of what I did for his son and that shoplifting is no big deal. I should have left them in jail!  Donald J. Trump (@realDonaldTrump) November 19, 2017Fox News put that tweet into a meme portraying Trump as a strong, decisive leader and the UCLA basketball players as weaklings, because of course they did. Then they asked:  Do you agree with President Trump? Yes. Fox News seriously asked people whether they agree that Trump should have left them in jail because the father of one is refusing to show proper gratitude:Do you agree with President @realDonaldTrump? pic.twitter.com/p3VdoXPxPG  Fox News (@FoxNews) November 20, 2017And Twitter is just not having this at all:Nope. He needs adoration- sign of insecurity. That s why he mocks others. Worthless. pic.twitter.com/XpI18s83Wx  Billy Depp (@ucla_007) November 20, 2017I ve never seen a Fox tweet critical of the president.All Fox is does is aid and abet insanity, hate and divisiveness that hurts America. pic.twitter.com/HrsATfLSMI  American Patriot (@RealPatriot1976) November 20, 2017It s all relative. Shoplifting is a crime but its totally eclipsed by Trump University.  Cody Swan (@Lampliighter) November 20, 2017Yeah, POTUS should only do his job if he gets his ass kissed properly. Are you high?  Bill Raudenbush (@CandidateBill) November 20, 2017No. He s a child!  Opinionated (@letmesharewithu) November 20, 2017nah i know what public service means   o  (@geofftype) November 20, 2017I think he should stop being petty af. I don t care to hear about this from the President of the United States. He s so insecure, it s beyond troubling.  Keisha Venezio (@keishhhha) November 20, 2017No, I don t agree  pic.twitter.com/7N9KI0oTxl  Kelly H (@Kellyk1969) November 20, 2017Do you agree with President @realDonaldTrump? pic.twitter.com/p3VdoXPxPG  Fox News (@FoxNews) November 20, 2017Nope. I personally would be extraordinarily appreciative if this happened to one of my kids, but i think it s shameful that the prez resents not being thanked enough and doesn t view helping Americans as just part of the job.  Liberal Kansan (@pvliberal) November 20, 2017NO Disgusting & embarrassing!  Melanie (@Melanie03630436) November 20, 2017Well, I m not convinced that he single-handedly got them out of jail  so the question isn t really valid  Isaac Simonelli (@DiceTravels) November 20, 2017No normal person does. And YOU know it.  Ernie Page (@AngryHatter) November 20, 2017What?! This man is a child in a rumpled suit. In case you haven t noticed, hardly anybody likes him. : Thus, when you give to the needy, sound no trumpet before you, as the hypocrites do in the synagogues and in the streets, that they may be praised by others.  pic.twitter.com/ntJzgkdWdz  DEMOS..We the people (@Windemere22) November 20, 2017China should have thrown #Dotard @realDonaldTrump into the slammer, chucked the key into the bog & flushed it away.  Holger  \\\\_( )_/  (@hnelke1973) November 20, 2017No. @realDonaldTrump has no idea what it means to do good for the sake of doing good. He is an empty shell of a man with no moral compass. Also not my favorite president.  Doreen Graham (@DoreeGraham) November 20, 2017Absolutely not. The fact that our narcissistic baby in chief can t take any criticism without lashing out is disgraceful. We deserve better  erin o (@erin0331) November 20, 2017Typical trump .. always about himself forgetting America is for all  SARA_PDaily (@sarapdaily) November 20, 2017Typical trump .. always about himself forgetting America is for all  SARA_PDaily (@sarapdaily) November 20, 2017Why would anyone agree with this shit? Remember when we mourned the death of the student who died in NK and now we re talking about this?  Aditya Sharma (@adityaksharma) November 20, 2017No I do not agree with Donald. As a matter of fact, I wish he was left in the hospital at the time of his birth.  RABell (@R_A_Bell) November 20, 2017President Man-Baby needs to grow up. And Fox News needs to stop feeding his bullshit.Featured image via Alex Wong/Getty Images', 'MOSCOW (Reuters) - Russia on Wednesday warned Iraq and the Kurds against taking any steps that might destabilize the Middle East after a Kurdish independence referendum, encouraging both sides to hold talks to find a solution within the framework of a single Iraqi state. The Russian Foreign Ministry, in the same statement, also said that while Moscow respected the Kurds  national ambitions it favored preserving the territorial integrity of Iraq. ', \"House Majority Whip Steve Scalise (R., La.) threw a strike in his ceremonial first pitch at the Washington National s opening-round playoff game Friday night, which was also his birthday.Scalise was shot in the hip and nearly died in June and he had to throw from a walker but he had no trouble delivering a perfect pitch to Capitol police special agent David Bailey, who was also injured in the shooting.After taking a bullet on a field in Alexandria, Va., Scalise was visibly happy to return to the diamond, and he expressed his gratefulness on Twitter after.What a memorable birthday! I threw the first pitch at tonight's @Nationals vs. @Cubs #NLDS game! pic.twitter.com/1F7XrRGwiP  Rep. Steve Scalise (@SteveScalise) October 7, 2017Scalise returned to the House of Representatives last week to warm greetings from his colleagues, and he expressed thankfulness for his recovery. It s only strengthened my faith in God, and it s really crystallized what shows up as the goodness in people,  he said.  I got to see that goodness in people, and so while some people might focus on a tragic event and an evil act, to me, all I ll remember are the thousands of acts and kindness and love that came out of this.  Read more: WFB\", 'It can be said that Late Show host Stephen Colbert clearly gives no f*cks about what Donald Trump thinks of him. In addition, if Trump were to decide to angry-tweet Colbert in retaliation, you know that Colbert would wear that Twitter fit as a badge of honor, as he should.Absolutely annihilating Trump, his connection to Putin, the Russian prostitute story, the fact that he wants to take a mini-vacation after the inauguration, and the fact that, well, he s clearly full of sh*t, Colbert didn t hold back even bringing God, yes that God almighty with a gun, into the mix.Colbert even brought up the fact that Trump s approval ratings are absolutely pathetic, especially when compared to President Obama s approval rating upon entering office. Not only that, but Colbert had to admit something terrible   that he and white supremacists have one thing in common, they are absolutely disappointed in Trump   albeit clearly for different reasons.The Late Show host even pointed out that Trump will blame everything on being rigged if it doesn t go his way. Even if the weather is bad on Inauguration Day, that s clearly a conspiracy against him.Watch Colbert absolutely shred Trump here:Featured image via video screen capture'], 'label': [0, 0, 1, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(ds[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23994b99-6665-49d4-beb6-f6ae2e0b4f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
      "    num_rows: 0\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(ds[\"train\"].filter(lambda x: x[\"text\"] is None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0f03d8a6-15cd-48a4-8f20-eec0c7dffa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.filter(lambda x: x[\"text\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "872db27f-67c7-4f34-8b1e-ddd474effa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(example):\n",
    "    example[\"text\"] = example[\"text\"].lower()\n",
    "    return example\n",
    "\n",
    "ds = ds.map(to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bf094d32-48a1-4513-9dac-788a880bd903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(example):\n",
    "    example[\"text\"] = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", example[\"text\"])\n",
    "    return example\n",
    "\n",
    "ds = ds.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fa0dfdbb-f622-40d6-813c-8f39d95b1dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.46.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prash\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5e0330b-4ff8-470b-84c0-a93a6a52c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "ds = ds.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cc1ba16c-317c-4cd6-9fa3-18f7008342c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e0ccaaf4-26fc-4943-8b22-dd512c48571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f58cbb12-1913-40e4-a02a-9f7f89bdc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example training data\n",
    "documents = [\"Sample text for training.\", \"Another sample text.\"]\n",
    "labels = [1, 0]  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b3d70265-651d-4cac-a760-82b6eea432db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ace19466-1e0d-4f49-83fe-fbe496b28954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e99fb66d-ee43-4eaa-8dff-6059254cfd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0e6b37ad-9aaf-402c-84cf-9384d0224d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(model, \"logistic_regression_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7e78d3af-d57b-425b-b220-a031db25c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9722849517552864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2207\n",
      "           1       0.98      0.97      0.97      2664\n",
      "\n",
      "    accuracy                           0.97      4871\n",
      "   macro avg       0.97      0.97      0.97      4871\n",
      "weighted avg       0.97      0.97      0.97      4871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset and split\n",
    "ds = load_dataset(\"GonzaloA/fake_news\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform([x[\"text\"] for x in ds[\"train\"]])\n",
    "X_test = vectorizer.transform([x[\"text\"] for x in ds[\"test\"]])\n",
    "\n",
    "# Extract labels\n",
    "y_train = [x[\"label\"] for x in ds[\"train\"]]\n",
    "y_test = [x[\"label\"] for x in ds[\"test\"]]\n",
    "\n",
    "# Train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "60ec97e7-22bd-4e23-867d-5d540de6af1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9780332580578937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2228\n",
      "           1       0.99      0.97      0.98      2643\n",
      "\n",
      "    accuracy                           0.98      4871\n",
      "   macro avg       0.98      0.98      0.98      4871\n",
      "weighted avg       0.98      0.98      0.98      4871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset and split\n",
    "ds = load_dataset(\"GonzaloA/fake_news\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform([x[\"text\"] for x in ds[\"train\"]])\n",
    "X_test = vectorizer.transform([x[\"text\"] for x in ds[\"test\"]])\n",
    "\n",
    "# Extract labels\n",
    "y_train = [x[\"label\"] for x in ds[\"train\"]]\n",
    "y_test = [x[\"label\"] for x in ds[\"test\"]]\n",
    "\n",
    "# Initialize and train the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = gb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4915baa9-d82f-40b0-a31f-14da1a010ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9848080476288237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2226\n",
      "           1       0.99      0.98      0.99      2645\n",
      "\n",
      "    accuracy                           0.98      4871\n",
      "   macro avg       0.98      0.99      0.98      4871\n",
      "weighted avg       0.98      0.98      0.98      4871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset and split\n",
    "ds = load_dataset(\"GonzaloA/fake_news\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform([x[\"text\"] for x in ds[\"train\"]])\n",
    "X_test = vectorizer.transform([x[\"text\"] for x in ds[\"test\"]])\n",
    "\n",
    "# Extract labels\n",
    "y_train = [x[\"label\"] for x in ds[\"train\"]]\n",
    "y_test = [x[\"label\"] for x in ds[\"test\"]]\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e96a4364-d555-4d2d-8d5d-454ab8e100f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9191131184561692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      2252\n",
      "           1       0.92      0.93      0.93      2619\n",
      "\n",
      "    accuracy                           0.92      4871\n",
      "   macro avg       0.92      0.92      0.92      4871\n",
      "weighted avg       0.92      0.92      0.92      4871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset and split\n",
    "ds = load_dataset(\"GonzaloA/fake_news\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform([x[\"text\"] for x in ds[\"train\"]])\n",
    "X_test = vectorizer.transform([x[\"text\"] for x in ds[\"test\"]])\n",
    "\n",
    "# Extract labels\n",
    "y_train = [x[\"label\"] for x in ds[\"train\"]]\n",
    "y_test = [x[\"label\"] for x in ds[\"test\"]]\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = nb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8232e55b-ec23-442b-80b9-203d63fb0983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      2224\n",
      "           1       0.97      0.97      0.97      2647\n",
      "\n",
      "    accuracy                           0.97      4871\n",
      "   macro avg       0.97      0.97      0.97      4871\n",
      "weighted avg       0.97      0.97      0.97      4871\n",
      "\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.9811\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      2224\n",
      "           1       0.99      0.97      0.98      2647\n",
      "\n",
      "    accuracy                           0.98      4871\n",
      "   macro avg       0.98      0.98      0.98      4871\n",
      "weighted avg       0.98      0.98      0.98      4871\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9791\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      2224\n",
      "           1       0.99      0.97      0.98      2647\n",
      "\n",
      "    accuracy                           0.98      4871\n",
      "   macro avg       0.98      0.98      0.98      4871\n",
      "weighted avg       0.98      0.98      0.98      4871\n",
      "\n",
      "==================================================\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.9130\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      2224\n",
      "           1       0.93      0.91      0.92      2647\n",
      "\n",
      "    accuracy                           0.91      4871\n",
      "   macro avg       0.91      0.91      0.91      4871\n",
      "weighted avg       0.91      0.91      0.91      4871\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"GonzaloA/fake_news\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform([x[\"text\"] for x in ds[\"train\"]])\n",
    "X_test = vectorizer.transform([x[\"text\"] for x in ds[\"test\"]])\n",
    "\n",
    "# Extract labels\n",
    "y_train = [x[\"label\"] for x in ds[\"train\"]]\n",
    "y_test = [x[\"label\"] for x in ds[\"test\"]]\n",
    "\n",
    "# Initialize each model\n",
    "log_reg_model = LogisticRegression(max_iter=1000)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train all models on the training data\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "gb_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# List of models for evaluation\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg_model,\n",
    "    \"Gradient Boosting\": gb_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"Naive Bayes\": nb_model\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print model's name, accuracy, and classification report\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8cde26fd-0f64-4051-a873-c198f9655907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_texts = [\n",
    "     \"Why is Elon Musk becoming Donald Trump's efficiency tsar Billionaire Elon Musk has been tasked with leading incoming President Donald Trump's new Department of Government Efficiency (Doge) In a statement on social media, the US president-elect said Musk - along with former Republican presidential candidate Vivek Ramaswamy - would dismantle government bureaucracy, slash excess regulations, cut wasteful expenditures and restructure federal agencies It is a role that the tech entrepreneur has arguably prepared for through his business leadership and one he has spent months arguing for But it is also one that is expected to garner him influence over government policy and the regulatory environment his enterprises exist in\"\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "83b0aa4f-6f21-48ad-adb8-9a5edbd7ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts_vectorized = vectorizer.transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f2a118c4-79e4-4a21-a7af-0b9db2d38e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Text 1: Real\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Text 1: Fake\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Text 1: Fake\n",
      "==================================================\n",
      "Model: Naive Bayes\n",
      "Text 1: Real\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def check_fake_news(models, new_texts_vectorized):\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(new_texts_vectorized)\n",
    "        \n",
    "        # Print out the predictions\n",
    "        print(f\"Model: {model_name}\")\n",
    "        for i, text in enumerate(new_texts):\n",
    "            print(f\"Text {i+1}: {'Fake' if y_pred[i] == 0 else 'Real'}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Check predictions (make sure this line is at the correct indentation level)\n",
    "check_fake_news(models, new_texts_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8580bf21-99cf-446f-abe2-00b8ace11645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training data\n",
    "X_train = vectorizer.fit_transform([x[\"text\"] for x in ds[\"train\"]])\n",
    "X_test = vectorizer.transform([x[\"text\"] for x in ds[\"test\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5a7c72a9-a82b-4e8b-9ca9-47ec8255a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize new text\n",
    "new_texts = [\"Your input text here\"]\n",
    "new_texts_vectorized = vectorizer.transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "654a6820-365a-44d6-8a29-3ee6adf41a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (19482, 5000)\n",
      "new_texts_vectorized shape: (1, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Check shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"new_texts_vectorized shape:\", new_texts_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a36fa7b8-377b-4bd0-8950-870b95d20649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression prediction: Fake\n",
      "Gradient Boosting prediction: Fake\n",
      "Random Forest prediction: Fake\n",
      "Naive Bayes prediction: Fake\n",
      "Model: Logistic Regression\n",
      "Text 1: Fake\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Text 1: Fake\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Text 1: Fake\n",
      "==================================================\n",
      "Model: Naive Bayes\n",
      "Text 1: Fake\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Predict with all models\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(new_texts_vectorized)\n",
    "    print(f\"{model_name} prediction: {'Fake' if y_pred[0] == 0 else 'Real'}\")\n",
    "\n",
    "def check_fake_news(models, new_texts_vectorized):\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(new_texts_vectorized)\n",
    "        \n",
    "        # Print out the predictions\n",
    "        print(f\"Model: {model_name}\")\n",
    "        for i, text in enumerate(new_texts):\n",
    "            print(f\"Text {i+1}: {'Fake' if y_pred[i] == 0 else 'Real'}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Check predictions (make sure this line is at the correct indentation level)\n",
    "check_fake_news(models, new_texts_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "03395118-f87b-4a2e-acf5-ece7eb00138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Article Text:\n",
      " \n",
      "\n",
      "Rare photo of the elusive tree octopus\n",
      "\n",
      "(Enhanced from cropped telephoto) Rare photo of the elusive tree octopus(Enhanced from cropped telephoto)\n",
      "\n",
      "The Pacific Northwest tree octopus (Octopus paxarbolis) can be found in the temperate rainforests of the Olympic Peninsula on the west coast of North America. Their habitat lies on the Eastern side of the Olympic mountain range, adjacent to Hood Canal. These solitary cephalopods reach an average size (measured from arm-tip to mantle-tip,) of 30-33 cm. Unlike most other cephalopods, tree octopuses are amphibious, spending only their early life and the period of their mating season in their ancestral aquatic environment. Because of the moistness of the rainforests and specialized skin adaptations, they are able to keep from becoming desiccated for prolonged periods of time, but given the chance they would prefer resting in pooled water.\n",
      "\n",
      "An intelligent and inquisitive being (it has the largest brain-to-body ratio for any mollusk), the tree octopus explores its arboreal world by both touch and sight. Adaptations its ancestors originally evolved in the three dimensional environment of the sea have been put to good use in the spatially complex maze of the coniferous Olympic rainforests. The challenges and richness of this environment (and the intimate way in which it interacts with it,) may account for the tree octopus's advanced behavioral development. (Some evolutionary theorists suppose that \"arboreal adaptation\" is what laid the groundwork in primates for the evolution of the human mind.)\n",
      "\n",
      "Reaching out with one of her eight arms, each covered in sensitive suckers, a tree octopus might grab a branch to pull herself along in a form of locomotion called tentaculation; or she might be preparing to strike at an insect or small vertebrate, such as a frog or rodent, or steal an egg from a bird's nest; or she might even be examining some object that caught her fancy, instinctively desiring to manipulate it with her dexterous limbs (really deserving the title \"sensory organs\" more than mere \"limbs\",) in order to better know it.\n",
      "\n",
      "\n",
      "\n",
      "Map of estimated tree octopus maximum range, including spawning waters Map of estimated tree octopus maximum range, including spawning waters\n",
      "\n",
      "Tree octopuses have eyesight comparable to humans. Besides allowing them to see their prey and environment, it helps them in inter-octopus relations. Although they are not social animals like us, they display to one-another their emotions through their ability to change the color of their skin: red indicates anger, white fear, while they normally maintain a mottled brown tone to blend in with the background.\n",
      "\n",
      "The reproductive cycle of the tree octopus is still linked to its roots in the waters of the Puget Sound from where it is thought to have originated. Every year, in Spring, tree octopuses leave their homes in the Olympic National Forest and migrate towards the shore and, eventually, their spawning grounds in Hood Canal. There, they congregate (the only real social time in their lives,) and find mates. After the male has deposited his sperm, he returns to the forests, leaving the female to find an aquatic lair in which to attach her strands of egg-clusters. The female will guard and care for her eggs until they hatch, refusing even to eat, and usually dying from her selflessness. The young will spend the first month or so floating through Hood Canal, Admiralty Inlet, and as far as North Puget Sound before eventually moving out of the water and beginning their adult lives.\n",
      "Model: Logistic Regression\n",
      "Prediction: Fake\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Prediction: Fake\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Prediction: Fake\n",
      "==================================================\n",
      "Model: Naive Bayes\n",
      "Prediction: Fake\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define function to extract article text from a URL\n",
    "def extract_article(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "# Example usage: Extract article text\n",
    "url = 'https://zapatopi.net/treeoctopus/'\n",
    "article_text = extract_article(url)\n",
    "\n",
    "# Print the extracted text\n",
    "print(\"Extracted Article Text:\\n\", article_text)\n",
    "\n",
    "# Assuming 'vectorizer' is already trained with your dataset\n",
    "# Vectorize the new article text\n",
    "new_text_vectorized = vectorizer.transform([article_text])\n",
    "\n",
    "# Function to check if the article is fake or real\n",
    "def check_fake_news(models, new_text_vectorized):\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(new_text_vectorized)\n",
    "        \n",
    "        # Print the prediction for each model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Prediction: {'Fake' if y_pred[0] == 0 else 'Real'}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Run the fake news check\n",
    "check_fake_news(models, new_text_vectorized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "613b83b7-0625-4bdb-b07e-0a31e18b1376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Article Text:\n",
      " MUMBAI: It seems that Sharad Pawar’s party, the NCP, faced significant challenges in the Assembly polls due to his failure to fulfill the promise of introducing fresh faces into the leadership and nurturing them, much like how Yashwantrao Chavan—Maharashtra’s first chief minister—mentored him.\n",
      "\n",
      "Buoyed by a massive victory in the recent Lok Sabha elections, Pawar had pledged to provide opportunities to younger candidates. However, in his own constituency of Baramati—first represented by him and later by his nephew, Ajit Pawar, since the 1960s—he chose to field his own 32-year-old grand-nephew, Yogendra Pawar, against his nephew and rival, Ajit Pawar, who is also the deputy chief minister.\n",
      "\n",
      "But the people opted for the more experienced Ajit Pawar. In the Lok Sabha election for the Baramati seat, Ajit Pawar’s wife, Sunetra Pawar, lost to Sharad Pawar’s daughter, Supriya Sule, by 150,000 votes. In the assembly segment, she trailed by 48,000 votes. Notably, in the state elections, Ajit Pawar won against his grand-nephew Yogendra by a significant margin of 1,00,899 votes.\n",
      "Model: Logistic Regression\n",
      "Prediction: Real\n",
      "==================================================\n",
      "Model: Gradient Boosting\n",
      "Prediction: Fake\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Prediction: Fake\n",
      "==================================================\n",
      "Model: Naive Bayes\n",
      "Prediction: Real\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define function to extract article text from a URL\n",
    "def extract_article(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "# Example usage: Extract article text\n",
    "url = 'https://www.newindianexpress.com/thesundaystandard/2024/Nov/24/future-tense-for-sharad-pawar-uddhav-thackeray'\n",
    "article_text = extract_article(url)\n",
    "\n",
    "# Print the extracted text\n",
    "print(\"Extracted Article Text:\\n\", article_text)\n",
    "\n",
    "# Assuming 'vectorizer' is already trained with your dataset\n",
    "# Vectorize the new article text\n",
    "new_text_vectorized = vectorizer.transform([article_text])\n",
    "\n",
    "# Function to check if the article is fake or real\n",
    "def check_fake_news(models, new_text_vectorized):\n",
    "    for model_name, model in models.items():\n",
    "        y_pred = model.predict(new_text_vectorized)\n",
    "        \n",
    "        # Print the prediction for each model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Prediction: {'Fake' if y_pred[0] == 0 else 'Real'}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Run the fake news check\n",
    "check_fake_news(models, new_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "98777c35-671c-4a91-bba8-d49ccb8f16e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Article Text:\n",
      " \n",
      "\n",
      "Rare photo of the elusive tree octopus\n",
      "\n",
      "(Enhanced from cropped telephoto) Rare photo of the elusive tree octopus(Enhanced from cropped telephoto)\n",
      "\n",
      "The Pacific Northwest tree octopus (Octopus paxarbolis) can be found in the temperate rainforests of the Olympic Peninsula on the west coast of North America. Their habitat lies on the Eastern side of the Olympic mountain range, adjacent to Hood Canal. These solitary cephalopods reach an average size (measured from arm-tip to mantle-tip,) of 30-33 cm. Unlike most other cephalopods, tree octopuses are amphibious, spending only their early life and the period of their mating season in their ancestral aquatic environment. Because of the moistness of the rainforests and specialized skin adaptations, they are able to keep from becoming desiccated for prolonged periods of time, but given the chance they would prefer resting in pooled water.\n",
      "\n",
      "An intelligent and inquisitive being (it has the largest brain-to-body ratio for any mollusk), the tree octopus explores its arboreal world by both touch and sight. Adaptations its ancestors originally evolved in the three dimensional environment of the sea have been put to good use in the spatially complex maze of the coniferous Olympic rainforests. The challenges and richness of this environment (and the intimate way in which it interacts with it,) may account for the tree octopus's advanced behavioral development. (Some evolutionary theorists suppose that \"arboreal adaptation\" is what laid the groundwork in primates for the evolution of the human mind.)\n",
      "\n",
      "Reaching out with one of her eight arms, each covered in sensitive suckers, a tree octopus might grab a branch to pull herself along in a form of locomotion called tentaculation; or she might be preparing to strike at an insect or small vertebrate, such as a frog or rodent, or steal an egg from a bird's nest; or she might even be examining some object that caught her fancy, instinctively desiring to manipulate it with her dexterous limbs (really deserving the title \"sensory organs\" more than mere \"limbs\",) in order to better know it.\n",
      "\n",
      "\n",
      "\n",
      "Map of estimated tree octopus maximum range, including spawning waters Map of estimated tree octopus maximum range, including spawning waters\n",
      "\n",
      "Tree octopuses have eyesight comparable to humans. Besides allowing them to see their prey and environment, it helps them in inter-octopus relations. Although they are not social animals like us, they display to one-another their emotions through their ability to change the color of their skin: red indicates anger, white fear, while they normally maintain a mottled brown tone to blend in with the background.\n",
      "\n",
      "The reproductive cycle of the tree octopus is still linked to its roots in the waters of the Puget Sound from where it is thought to have originated. Every year, in Spring, tree octopuses leave their homes in the Olympic National Forest and migrate towards the shore and, eventually, their spawning grounds in Hood Canal. There, they congregate (the only real social time in their lives,) and find mates. After the male has deposited his sperm, he returns to the forests, leaving the female to find an aquatic lair in which to attach her strands of egg-clusters. The female will guard and care for her eggs until they hatch, refusing even to eat, and usually dying from her selflessness. The young will spend the first month or so floating through Hood Canal, Admiralty Inlet, and as far as North Puget Sound before eventually moving out of the water and beginning their adult lives.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but LogisticRegression is expecting 5000 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 74\u001b[0m\n\u001b[0;32m     66\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_reg_model,  \u001b[38;5;66;03m# Your trained Logistic Regression model\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient Boosting\u001b[39m\u001b[38;5;124m\"\u001b[39m: gb_model,        \u001b[38;5;66;03m# Your trained Gradient Boosting model\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: rf_model,            \u001b[38;5;66;03m# Your trained Random Forest model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: nb_model               \u001b[38;5;66;03m# Your trained Naive Bayes model\u001b[39;00m\n\u001b[0;32m     71\u001b[0m }\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Run the fake news check with weighted decision\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m final_result \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_fake_news_weighted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_text_vectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_accuracies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[153], line 41\u001b[0m, in \u001b[0;36mcheck_fake_news_weighted\u001b[1;34m(models, new_text_vectorized, model_accuracies)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (model_name, model) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Ensure model is using the same feature vector dimensions as the training set\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# For classifiers that provide probabilities, use probabilities to weight predictions\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m         prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_text_vectorized\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Get probability of the positive class\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Convert probability to binary prediction (0 or 1)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;66;03m# For classifiers that don't provide probabilities, use direct prediction\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1431\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1423\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1425\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1428\u001b[0m     )\n\u001b[0;32m   1429\u001b[0m )\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[1;32m-> 1431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1433\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:397\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    398\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:363\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    361\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 363\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4 features, but LogisticRegression is expecting 5000 features as input."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from newspaper import Article\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define function to extract article text from a URL\n",
    "def extract_article(url):\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    return article.text\n",
    "\n",
    "# Example usage: Extract article text from the provided URL\n",
    "url = 'https://zapatopi.net/treeoctopus/'  # Example article URL\n",
    "article_text = extract_article(url)\n",
    "\n",
    "# Print the extracted text\n",
    "print(\"Extracted Article Text:\\n\", article_text)\n",
    "\n",
    "# Example training data (This should be your actual comprehensive training dataset)\n",
    "training_data = [\n",
    "    \"text of news article 1\", \n",
    "    \"text of news article 2\", \n",
    "    \"text of news article 3\",\n",
    "    article_text  # Include the new text in the training data\n",
    "]\n",
    "\n",
    "# Create and fit the vectorizer with a fixed vocabulary size\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Explicitly set max_features to match your model's expectation\n",
    "\n",
    "# Fit the vectorizer on the training data\n",
    "vectorizer.fit(training_data)\n",
    "\n",
    "# Vectorize the new article text using the fitted vectorizer\n",
    "new_text_vectorized = vectorizer.transform([article_text])\n",
    "\n",
    "# Verify the dimensions of the vectorized text\n",
    "print(f\"Vectorized text shape: {new_text_vectorized.shape}\")\n",
    "\n",
    "# Define the model accuracies (these should match the models you're using)\n",
    "model_accuracies = [0.9717, 0.9811, 0.9780, 0.9230]  # Logistic Regression, Gradient Boosting, Random Forest, Naive Bayes\n",
    "\n",
    "# Function to check if the article is fake or real with weighted decision\n",
    "def check_fake_news_weighted(models, new_text_vectorized, model_accuracies):\n",
    "    model_predictions = []\n",
    "\n",
    "    # Get predictions from each model\n",
    "    for i, (model_name, model) in enumerate(models.items()):\n",
    "        # Ensure model is using the same feature vector dimensions as the training set\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            # For classifiers that provide probabilities, use probabilities to weight predictions\n",
    "            prob = model.predict_proba(new_text_vectorized)[0, 1]  # Get probability of the positive class\n",
    "            prediction = 1 if prob > 0.5 else 0  # Convert probability to binary prediction (0 or 1)\n",
    "        else:\n",
    "            # For classifiers that don't provide probabilities, use direct prediction\n",
    "            prediction = model.predict(new_text_vectorized)[0]\n",
    "        \n",
    "        model_predictions.append(prediction)  # Store the prediction of the first (and only) text\n",
    "\n",
    "    # Initialize weighted sum of predictions\n",
    "    weighted_sum = 0\n",
    "\n",
    "    # Calculate the weighted sum of the predictions based on accuracies\n",
    "    for i, prediction in enumerate(model_predictions):\n",
    "        weighted_sum += prediction * model_accuracies[i]  # Multiply each model's prediction by its accuracy (weight)\n",
    "\n",
    "    # Final decision: sum of weighted predictions\n",
    "    if weighted_sum > 0:\n",
    "        final_prediction = 1  # Consider \"Real\" if weighted sum is positive\n",
    "    else:\n",
    "        final_prediction = 0  # Consider \"Fake\" if weighted sum is zero or negative\n",
    "    \n",
    "    return 'Real' if final_prediction == 1 else 'Fake'\n",
    "\n",
    "# Example models (These need to be defined or loaded based on your previous code)\n",
    "# Assuming you already have these models loaded and trained:\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg_model,  # Your trained Logistic Regression model\n",
    "    \"Gradient Boosting\": gb_model,        # Your trained Gradient Boosting model\n",
    "    \"Random Forest\": rf_model,            # Your trained Random Forest model\n",
    "    \"Naive Bayes\": nb_model               # Your trained Naive Bayes model\n",
    "}\n",
    "\n",
    "# Run the fake news check with weighted decision\n",
    "final_result = check_fake_news_weighted(models, new_text_vectorized, model_accuracies)\n",
    "print(f\"Final Prediction: {final_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ee3f3d2-2c41-46b5-8112-93db7e2fed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c4fbede-e968-4bd7-9a60-62cd212e3e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6000f3a3-42ad-46b2-9500-f9099697e46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Rare photo of the elusive tree octopus\n",
      "\n",
      "(Enhanced from cropped telephoto) Rare photo of the elusive tree octopus(Enhanced from cropped telephoto)\n",
      "\n",
      "The Pacific Northwest tree octopus (Octopus paxarbolis) can be found in the temperate rainforests of the Olympic Peninsula on the west coast of North America. Their habitat lies on the Eastern side of the Olympic mountain range, adjacent to Hood Canal. These solitary cephalopods reach an average size (measured from arm-tip to mantle-tip,) of 30-33 cm. Unlike most other cephalopods, tree octopuses are amphibious, spending only their early life and the period of their mating season in their ancestral aquatic environment. Because of the moistness of the rainforests and specialized skin adaptations, they are able to keep from becoming desiccated for prolonged periods of time, but given the chance they would prefer resting in pooled water.\n",
      "\n",
      "An intelligent and inquisitive being (it has the largest brain-to-body ratio for any mollusk), the tree octopus explores its arboreal world by both touch and sight. Adaptations its ancestors originally evolved in the three dimensional environment of the sea have been put to good use in the spatially complex maze of the coniferous Olympic rainforests. The challenges and richness of this environment (and the intimate way in which it interacts with it,) may account for the tree octopus's advanced behavioral development. (Some evolutionary theorists suppose that \"arboreal adaptation\" is what laid the groundwork in primates for the evolution of the human mind.)\n",
      "\n",
      "Reaching out with one of her eight arms, each covered in sensitive suckers, a tree octopus might grab a branch to pull herself along in a form of locomotion called tentaculation; or she might be preparing to strike at an insect or small vertebrate, such as a frog or rodent, or steal an egg from a bird's nest; or she might even be examining some object that caught her fancy, instinctively desiring to manipulate it with her dexterous limbs (really deserving the title \"sensory organs\" more than mere \"limbs\",) in order to better know it.\n",
      "\n",
      "\n",
      "\n",
      "Map of estimated tree octopus maximum range, including spawning waters Map of estimated tree octopus maximum range, including spawning waters\n",
      "\n",
      "Tree octopuses have eyesight comparable to humans. Besides allowing them to see their prey and environment, it helps them in inter-octopus relations. Although they are not social animals like us, they display to one-another their emotions through their ability to change the color of their skin: red indicates anger, white fear, while they normally maintain a mottled brown tone to blend in with the background.\n",
      "\n",
      "The reproductive cycle of the tree octopus is still linked to its roots in the waters of the Puget Sound from where it is thought to have originated. Every year, in Spring, tree octopuses leave their homes in the Olympic National Forest and migrate towards the shore and, eventually, their spawning grounds in Hood Canal. There, they congregate (the only real social time in their lives,) and find mates. After the male has deposited his sperm, he returns to the forests, leaving the female to find an aquatic lair in which to attach her strands of egg-clusters. The female will guard and care for her eggs until they hatch, refusing even to eat, and usually dying from her selflessness. The young will spend the first month or so floating through Hood Canal, Admiralty Inlet, and as far as North Puget Sound before eventually moving out of the water and beginning their adult lives.\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "url = \"https://zapatopi.net/treeoctopus/\"\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()\n",
    "print(article.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ec9ef-a6e2-4781-a110-e00beba42a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
